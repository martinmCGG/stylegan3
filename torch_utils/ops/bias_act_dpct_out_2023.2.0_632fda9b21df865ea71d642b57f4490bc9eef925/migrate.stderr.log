warning: /home/martin/.cache/torch_extensions/bias_act_plugin/9936501c2690d15987a56ecc20fa04e5-nvidia-rtx-a6000/bias_act.o: 'linker' input unused [-Wunused-command-line-argument]
warning: bias_act.cuda.o: 'linker' input unused [-Wunused-command-line-argument]
warning: -lc10: 'linker' input unused [-Wunused-command-line-argument]
warning: -lc10_cuda: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch_cpu: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch_cuda_cu: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch_cuda_cpp: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch_python: 'linker' input unused [-Wunused-command-line-argument]
warning: -lcudart: 'linker' input unused [-Wunused-command-line-argument]
warning: argument unused during migration: '-Xclang -fcuda-allow-variadic-functions' [-Wunused-command-line-argument]
warning: argument unused during migration: '-D __NVCC__' [-Wunused-command-line-argument]
warning: argument unused during migration: '-D __CUDACC_VER_MINOR__=0' [-Wunused-command-line-argument]
warning: argument unused during migration: '-D __CUDACC_VER_MAJOR__=12' [-Wunused-command-line-argument]
warning: argument unused during migration: '-nocudalib' [-Wunused-command-line-argument]
warning: argument unused during migration: '-I /usr/local/cuda-12.0/targets/x86_64-linux/include' [-Wunused-command-line-argument]
warning: argument unused during migration: '-shared' [-Wunused-command-line-argument]
warning: argument unused during migration: '-L/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/lib' [-Wunused-command-line-argument]
warning: argument unused during migration: '-L/usr/local/cuda-12.0/lib64' [-Wunused-command-line-argument]
error: unable to handle migration, expected exactly one migration job in ''
error: unsupported option '--expt-relaxed-constexpr'
error: unsupported option '--compiler-options'
error: unsupported option '--use_fast_math'
error: unsupported option '--allow-unsupported-compiler'
error: unknown argument: '-gencode=arch=compute_86,code=compute_86'
error: unknown argument: '-gencode=arch=compute_86,code=sm_86'
/home/martin/.cache/torch_extensions/bias_act_plugin/9936501c2690d15987a56ecc20fa04e5-nvidia-rtx-a6000/bias_act.cu:24:1: warning: DPCT1110:0: The total declared local variable size in device function bias_act_kernel exceeds 128 bytes and may cause high register pressure. Consult with your hardware vendor to find the total register size available and adjust the code, or use smaller sub-group size to avoid high register pressure.
__device__ void bias_act_kernel(bias_act_kernel_params p)
^
/home/martin/.cache/torch_extensions/bias_act_plugin/9936501c2690d15987a56ecc20fa04e5-nvidia-rtx-a6000/bias_act.cpp:89:9: warning: DPCT1049:1: The work-group size passed to the SYCL kernel may exceed the limit. To get the device limit, query info::device::max_work_group_size. Adjust the work-group size if needed.
        cudaLaunchKernel((void*)&bias_act_kernel_half, gridSize, blockSize, args, 0, at::cuda::getCurrentCUDAStream());
        ^
/home/martin/.cache/torch_extensions/bias_act_plugin/9936501c2690d15987a56ecc20fa04e5-nvidia-rtx-a6000/bias_act.cpp:91:9: warning: DPCT1049:2: The work-group size passed to the SYCL kernel may exceed the limit. To get the device limit, query info::device::max_work_group_size. Adjust the work-group size if needed.
        cudaLaunchKernel((void*)&bias_act_kernel_float, gridSize, blockSize, args, 0, at::cuda::getCurrentCUDAStream());
        ^
/home/martin/.cache/torch_extensions/bias_act_plugin/9936501c2690d15987a56ecc20fa04e5-nvidia-rtx-a6000/bias_act.cpp:93:9: warning: DPCT1049:3: The work-group size passed to the SYCL kernel may exceed the limit. To get the device limit, query info::device::max_work_group_size. Adjust the work-group size if needed.
        cudaLaunchKernel((void*)&bias_act_kernel_double, gridSize, blockSize, args, 0, at::cuda::getCurrentCUDAStream());
        ^
Saved new version of /home/martin/intel_hackathon/stylegan3/torch_utils/ops/bias_act_dpct_out_2023.2.0_632fda9b21df865ea71d642b57f4490bc9eef925/bias_act.h.yaml file

