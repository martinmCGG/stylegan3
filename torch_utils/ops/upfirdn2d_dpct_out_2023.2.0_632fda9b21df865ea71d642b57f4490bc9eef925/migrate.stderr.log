error: unsupported option '--expt-relaxed-constexpr'
error: unsupported option '--compiler-options'
error: unsupported option '--use_fast_math'
error: unsupported option '--allow-unsupported-compiler'
error: unknown argument: '-gencode=arch=compute_86,code=compute_86'
error: unknown argument: '-gencode=arch=compute_86,code=sm_86'
warning: /home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.o: 'linker' input unused [-Wunused-command-line-argument]
warning: upfirdn2d.cuda.o: 'linker' input unused [-Wunused-command-line-argument]
warning: -lc10: 'linker' input unused [-Wunused-command-line-argument]
warning: -lc10_cuda: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch_cpu: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch_cuda_cu: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch_cuda_cpp: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch: 'linker' input unused [-Wunused-command-line-argument]
warning: -ltorch_python: 'linker' input unused [-Wunused-command-line-argument]
warning: -lcudart: 'linker' input unused [-Wunused-command-line-argument]
warning: argument unused during migration: '-Xclang -fcuda-allow-variadic-functions' [-Wunused-command-line-argument]
warning: argument unused during migration: '-D __NVCC__' [-Wunused-command-line-argument]
warning: argument unused during migration: '-D __CUDACC_VER_MINOR__=0' [-Wunused-command-line-argument]
warning: argument unused during migration: '-D __CUDACC_VER_MAJOR__=12' [-Wunused-command-line-argument]
warning: argument unused during migration: '-nocudalib' [-Wunused-command-line-argument]
warning: argument unused during migration: '-I /usr/local/cuda-12.0/targets/x86_64-linux/include' [-Wunused-command-line-argument]
warning: argument unused during migration: '-shared' [-Wunused-command-line-argument]
warning: argument unused during migration: '-L/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/lib' [-Wunused-command-line-argument]
warning: argument unused during migration: '-L/usr/local/cuda-12.0/lib64' [-Wunused-command-line-argument]
error: unable to handle migration, expected exactly one migration job in ''
/home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.cu:98:1: warning: DPCT1110:0: The total declared local variable size in device function upfirdn2d_kernel_small exceeds 128 bytes and may cause high register pressure. Consult with your hardware vendor to find the total register size available and adjust the code, or use smaller sub-group size to avoid high register pressure.
static __global__ void upfirdn2d_kernel_small(upfirdn2d_kernel_params p)
^
/home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.cu:145:13: warning: DPCT1065:1: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.
            __syncthreads();
            ^
/home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.cu:163:13: warning: DPCT1065:2: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.
            __syncthreads();
            ^
/home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.cpp:96:19: warning: DPCT1007:3: Migration of cudaLaunchKernel is not supported.
    AT_CUDA_CHECK(cudaLaunchKernel(spec.kernel, gridSize, blockSize, args, 0, at::cuda::getCurrentCUDAStream()));
                  ^
/home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.cpp:96:5: warning: DPCT1001:4: The statement could not be removed.
    AT_CUDA_CHECK(cudaLaunchKernel(spec.kernel, gridSize, blockSize, args, 0, at::cuda::getCurrentCUDAStream()));
    ^
/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/ATen/cuda/Exceptions.h:85:29: note: expanded from macro 'AT_CUDA_CHECK'
#define AT_CUDA_CHECK(EXPR) C10_CUDA_CHECK(EXPR)
                            ^
/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/c10/cuda/CUDAException.h:42:7: note: expanded from macro 'C10_CUDA_CHECK'
      throw c10::CUDAError(                                         \
      ^
/home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.cpp:96:5: warning: DPCT1000:5: Error handling if-stmt was detected but could not be rewritten.
/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/ATen/cuda/Exceptions.h:85:29: note: expanded from macro 'AT_CUDA_CHECK'
#define AT_CUDA_CHECK(EXPR) C10_CUDA_CHECK(EXPR)
                            ^
/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/c10/cuda/CUDAException.h:39:5: note: expanded from macro 'C10_CUDA_CHECK'
    if (__err != cudaSuccess) {                                     \
    ^
/home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.cpp:96:5: warning: DPCT1010:6: SYCL uses exceptions to report errors and does not use the error codes. The call was replaced with 0. You need to rewrite this code.
/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/ATen/cuda/Exceptions.h:85:29: note: expanded from macro 'AT_CUDA_CHECK'
#define AT_CUDA_CHECK(EXPR) C10_CUDA_CHECK(EXPR)
                            ^
/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/c10/cuda/CUDAException.h:40:38: note: expanded from macro 'C10_CUDA_CHECK'
      auto error_unused C10_UNUSED = cudaGetLastError();            \
                                     ^
/home/martin/.cache/torch_extensions/upfirdn2d_plugin/7edf9e6a584689218f8aa5314b3a0356-nvidia-rtx-a6000/upfirdn2d.cpp:96:5: warning: DPCT1009:7: SYCL uses exceptions to report errors and does not use the error codes. The original code was commented out and a warning string was inserted. You need to rewrite this code.
/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/ATen/cuda/Exceptions.h:85:29: note: expanded from macro 'AT_CUDA_CHECK'
#define AT_CUDA_CHECK(EXPR) C10_CUDA_CHECK(EXPR)
                            ^
/home/martin/miniconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/c10/cuda/CUDAException.h:48:15: note: expanded from macro 'C10_CUDA_CHECK'
              cudaGetErrorString(__err),                            \
              ^
Saved new version of /home/martin/intel_hackathon/stylegan3/torch_utils/ops/upfirdn2d_dpct_out_2023.2.0_632fda9b21df865ea71d642b57f4490bc9eef925/upfirdn2d.h.yaml file

